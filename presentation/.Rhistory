x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
(x - mean(x))
(x - mean(x)) / sd(x)
rm(list=ls())
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y ~ x)$coef
help(mtcars)
# Question 1
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y~x)
summary(fit)
# Answer: 0.05296
# Question 2
# Answer: 0.223
# Question 3
# Use lm(mpg ~ wt) on the data(mtcars) and get the coefficients.
data(mtcars)
fit <- lm(mpg~wt, data=mtcars)
summary(fit)
mean_weight <- data.frame(wt = c(mean(mtcars$wt)))
predict(fit, mean_weight, interval='confidence')
# Answer: 18.99098
# Question 4
# wt is Weight (lb/1000)
help(mtcars)
# Answer: The estimated expected change in mpg per 1,000 lb increase in weight.
# Question 5
# The new data point is a car weighing 3000 lbs. The model variable is per 1000 lbs so divide.
# The prediction interval of the mean weight outcome.
data(mtcars)
fit <- lm(mpg~wt, data=mtcars)
summary(fit)
new_weight <- data.frame(wt = c(3000/1000))
predict(fit, new_weight, interval='prediction')
# Answer: 27.57355
# Question 6
# The new data point is a car weighing one short ton lbs. A short ton is defined as 2 000 lbs.
# This is the confidence interval around the weight coefficient and we must divide by two to
# rescale the weight values and slope cofficient.
data(mtcars)
y <- mtcars$mpg
x <- mtcars$wt / 2
fit <- lm(y~x)
summary(fit)
confint(fit)
# Answer: -12.97262
# Question 7
# If my X from a linear regression is measured in centimeters and
# I convert it to meters what would happen to the slope coefficient?
# Multiply by 1m / 100 cm to convet the units which means the slope
# coefficient is multiplied by 100.
# Question 8
# beta_zero_hat - c*beta_one_hat as the slope does not change with a shift in X values.
# Question 9
# Use lm to fit two linear models one with intercept and weight, and the other just with the
# intercept.
# Then use the resid.lm function and sum the squares and compute the ratio.
data(mtcars)
fit_with <- lm(mpg~wt+1, data=mtcars)
fit_without <- lm(mpg~1, data=mtcars)
ratio_of_residuals <- sum(resid(fit_with)^2)/sum(resid(fit_without)^2)
ratio_of_residuals
# Answer: 0.2471672
# Question 10
# If an intercept is included, then they will sum to 0.
rm(list=ls());
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y~x)
summary(fit)
fit
summary.p-value(fit)
summary(fit).pval
summary
help("summary")
summary(fit)$coefficients[2,4]
data(mtcars)
fit <- lm(mpg ~ factor(cyl) + wt, mtcars)
summary(fit)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y~x)
lm.influence(fit)$hat
dfbetas(fit)
rm(list=ls())
reset
install.packages("swirl")
library(swirl)
swirl()
install_from_swirl("Regression Models")
swirl()
plot(child ~ parent, galton)
plot(jitter(child,4) ~ parent,galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd=3, col='red')
summary(regrline)
fit <- lm(child ~ parent, galton)
summary(fit)
mean(fit$residuals)
cov(fit$residuals,galton$parent)
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
lhs-rhs
all.equal(lhs,rhs)
varChild <- var(galton$child)
varRes <- var(fit$residuals)
varEst <- var(est(ols.slope, ols.ic))
all.equal(varChild,varEst+varRes)
efit <- lm(accel ~ mag+dist, attenu)
mean(efit$residuals)
cov(efit$residuals, attenu$mag)','cov(attenu$mag,efit$residuals)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$dist)
cor(gpa_nor,gch_nor)
l_nor <- lm(gch_nor ~ gpa_nor)
fit <- lm(child ~ parent, galton)
sqrt(sum(fit$residuals^2) / (n - 2))
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
mu <- mean(galton$child)
sTot <- sum((galton$child-mu)^2)
sRes <- deviance(fit)
1-sRes/sTot
summary(fit)$r.squared
cor(galton$parent,galton$child)^2
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent - 1, galton)
lm(child ~ parent, galton)
lm(child ~ 1, galton)
head(trees)
fit <- lm(Volume ~ . - 1, trees)
trees2 <- eliminate("Girth", trees)
head(trees2)
fit2 <- lm(Volume ~ . - 1, trees2)
lapply(list(fit, fit2), coef)
data(mtcars)
attach(mtcars)
fit <- lm(mpg ~ as.factor(cyl) + wt, data=mtcars)
summary(fit)
[still very popular in Europe](http://www.dctfacts.com/archive/2008/why-dual-clutch-technology-big-business.aspx).
install.packages("plyr")
install.packages("ggplot2")
```{r warning=FALSE, results='hide' }
```{r warning=FALSE, results='hide' }
```{r warning=FALSE, results='hide' }
```{r warning=FALSE, results='hide' }
# factor some variables
mtcars$cyl <- factor(mtcars$cyl)
mtcars$vs <- factor(mtcars$vs)
mtcars$am <- factor(mtcars$am)
mtcars$gear <- factor(mtcars$gear)
mtcars$carb <- factor(mtcars$carb)
str(mtcars)
```
```{r warning=FALSE, results='hide'}
#factor some variables
mtcars$cyl <- factor(mtcars$cyl)
mtcars$vs <- factor(mtcars$vs)
mtcars$am <- factor(mtcars$am)
mtcars$gear <- factor(mtcars$gear)
mtcars$carb <- factor(mtcars$carb)
str(mtcars)
```
```{r, results='hide'}
result <- t.test(mpg ~ am)
result$p.value
result$estimate
```
initial_model <- lm(mpg ~ ., data=mtcars)
best_model <- step(initial_model, direction="both", trace=0)
summary(best_model)
par(mfrow = c(2,2))
plot(best_model)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages(c("AppliedPredictiveModeling", "caret"))
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
rm(list=ls())
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[trainIndex,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p=3/4)[[1]]
training = mixtures[inTrain,]
testing = mixtures[-inTrain,]
xnames <- colnames(concrete)[1:8]
featurePlot(x=training[, xnames], y=training$CompressiveStrength, plot="pairs")
# No relation between the outcome and other variables
index <- seq_along(1:nrow(training))
ggplot(data=training, aes(x=index, y=CompressiveStrength)) + geom_point() +
theme_bw()
# Step-like pattern -> 4 categories
library(Hmisc)
cutCompressiveStrength <- cut2(training$CompressiveStrength, g=4)
summary(cutCompressiveStrength)
ggplot(data=training, aes(y=index, x=cutCompressiveStrength)) +
geom_boxplot() + geom_jitter(col="blue") + theme_bw()
# Another way
library(plyr)
splitOn <- cut2(training$Age, g=4)
splitOn <- mapvalues(splitOn,
from=levels(factor(splitOn)),
to=c("red", "blue", "yellow", "green"))
plot(training$CompressiveStrength, col=splitOn)
install.packages("Hmisc")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p=3/4)[[1]]
training = mixtures[inTrain,]
testing = mixtures[-inTrain,]
xnames <- colnames(concrete)[1:8]
featurePlot(x=training[, xnames], y=training$CompressiveStrength, plot="pairs")
# No relation between the outcome and other variables
index <- seq_along(1:nrow(training))
ggplot(data=training, aes(x=index, y=CompressiveStrength)) + geom_point() +
theme_bw()
# Step-like pattern -> 4 categories
library(Hmisc)
cutCompressiveStrength <- cut2(training$CompressiveStrength, g=4)
summary(cutCompressiveStrength)
ggplot(data=training, aes(y=index, x=cutCompressiveStrength)) +
geom_boxplot() + geom_jitter(col="blue") + theme_bw()
# Another way
library(plyr)
splitOn <- cut2(training$Age, g=4)
splitOn <- mapvalues(splitOn,
from=levels(factor(splitOn)),
to=c("red", "blue", "yellow", "green"))
plot(training$CompressiveStrength, col=splitOn)
library(Hmisc)
cutCompressiveStrength <- cut2(training$CompressiveStrength, g=4)
summary(cutCompressiveStrength)
ggplot(data=training, aes(y=index, x=cutCompressiveStrength)) +
geom_boxplot() + geom_jitter(col="blue") + theme_bw()
rm(list=ls())
install.packages("data.table")
install.packages("models")
install.packages("modeltools")
library(modeltools)
install.packages("randomForest")
install.packages("caret")
library("curl", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("data.table", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("gridExtra", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("profileModel", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("RCurl", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("randomForest", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("tools", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("knitr", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("AppliedPredictiveModeling", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.packages("e1071", lib="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.packages('devtools')
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='seamuss', token='D274DE1D5660EDA32F6751730637E740', secret='xL7F/gadM5blYp6Bw39O9hCDKJonRZNzTcZ4blOA')
library(rsconnect)
devtools::install_github('rstudio/rsconnect')
library(rsconnect)
shinyapps::setAccountInfo(name='seamuss', token='D274DE1D5660EDA32F6751730637E740', secret='xL7F/gadM5blYp6Bw39O9hCDKJonRZNzTcZ4blOA')
install.packages(c('ggplot2', 'shiny'))]
install.packages(c('ggplot2', 'shiny'))
library(shiny)
runApp()
shinyapps::setAccountInfo(name='seamuss', token='D274DE1D5660EDA32F6751730637E740', secret='xL7F/gadM5blYp6Bw39O9hCDKJonRZNzTcZ4blOA')
runApp()
setwd("~/Documents/dev-data-products")
runApp()
library(shinyapps)
shinyapps::deployApp('/Users/seamuss/Documents/dev-data-products')
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
library(shinyapps)
shinyapps::deployApp('/Users/seamuss/Documents/DevelopingDataProducts')
shinyapps::setAccountInfo(name='seamuss', token='D274DE1D5660EDA32F6751730637E740', secret='xL7F/gadM5blYp6Bw39O9hCDKJonRZNzTcZ4blOA')
setwd("~/Documents/DevelopingDataProducts")
setwd("~/Documents/dev-data-products")
setwd("~/Documents/DevelopingDataProducts")
shiny::runApp()
shiny::runApp()
library(rsconnect)
setwd("~/Documents/DevelopingDataProducts")
shinyapps::setAccountInfo(name='seamuss', token='AC52F249BE66E6C924C5B1475100062F', secret='EZ6epIbAVVsrBPa3qbWXNdcSTM5FisdZR476cKlV')
library(shinyapps)
shinyapps::deployApp('/Users/seamuss/Documents/DevelopingDataProducts')
shiny::runApp()
shiny::runApp('~/Documents/DevelopingDataProducts')
shiny::runApp('~/Documents/DevelopingDataProducts')
shiny::runApp('~/Documents/DevelopingDataProducts')
shiny::runApp('~/Documents/DevelopingDataProducts')
setwd("~/Documents/DevelopingDataProducts/presentation")
install.packages("slidify::knit2slides", lib="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
slidify::knit2slides
install.packages("slidify", lib="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.packages("devtools")
install.packages("devtools")
library(devtools)
install.packages("slidify", lib="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
pkgs <- c('ramnathv/slidifyLibraries', 'ramnathv/slidify')
devtools::install_github(pkgs)
publish(title = 'Developing Data Products Presentation', 'index.html', host = 'rpubs')
setwd("~/Documents/DevelopingDataProducts/presentation")
setwd("~/Documents/DevelopingDataProducts/presentation")
publish(title = 'Developing Data Products Presentation', 'index.html', host = 'rpubs')
publish(title = 'Developing Data Products Presentation', 'index.html', host = 'rpubs')
